---
layout: post
title: Example-Restricted Boltzmann Machine
category : docs
tags : [rbm, example]
---
{% include JB/setup %}

This example uses SINGA to train 4 RBM models and one auto-encoder model over the
[MNIST dataset](http://yann.lecun.com/exdb/mnist/). The auto-encoder model is trained
to reduce the dimensionality of the MNIST image feature. The RBM models are trained
to initialize parameters of the auto-encoder model. This example application is
from [Hinton's science paper](http://www.cs.toronto.edu/~hinton/science.pdf).

## Running instructions

Running scripts are provided in *SINGA_ROOT/examples/rbm* folder.

The MNIST dataset has 70,000 handwritten digit images. The
[data preparation]({{ BASE_PATH }}/docs/data) page
has details on converting this dataset into SINGA recognizable format (i.e.,
[DataShard]({{ BASE_PATH }}/api/classsinga_1_1DataShard.html)). Users can
simply run the following commands to download and convert the dataset.

    # at SINGA_ROOT/examples/rbm/
    $ cp Makefile.example Makefile
    $ make download
    $ make create

The training is separated into two phases, namely pre-training and fine-tuning.
The pre-training phase trains 4 RBMs in sequence,

    # at SINGA_ROOT/
    $ ./bin/singa-run.sh -conf examples/rbm/rbm0.conf
    $ ./bin/singa-run.sh -conf examples/rbm/rbm1.conf
    $ ./bin/singa-run.sh -conf examples/rbm/rbm2.conf
    $ ./bin/singa-run.sh -conf examples/rbm/rbm3.conf

The fine-tuning phase trains the auto-encoder by,

    $ ./bin/singa-run.sh -conf examples/rbm/autoencoder.conf


## Training details

### RBM0

<img src="{{ BASE_PATH }}/assets/image/RBM0.PNG" align="center" width="300px"/>
<span><strong>Figure 1 - RBM0.</strong></span>

The neural net structure for training RBM0 is shown in Figure 1.
The data layer and parser layer provides features for training RBM0.
The visible layer (connected with parser layer) of RBM0 accepts the image feature
(784 dimension). The hidden layer is set to have 1000 neurons (units).
These two layers are configured as,

    layer{
      name: "RBMVis"
      type: kRBMVis
      srclayers:"sigmoid2"
      srclayers:"RBMHid"
      rbmvis_conf{
        num_output: 250
      }
      param{
        name: "w3"
        init{
          type: kGaussian
          mean: 0.0
          std: 0.1
        }
      }
      param{
        name: "rb31"
        init{
          type: kConstant
          value: 0.0
        }
      }
    }

    layer{
      name: "RBMHid"
      type: kRBMHid
      srclayers:"RBMVis"
      rbmhid_conf{
        hid_dim: 250
      }
      param{
        name: "w3_1"
        share_from: "w3"
      }
      param{
        name: "rb32"
        init{
          type: kConstant
          value: 0.0
        }
      }
    }



For RBM, the weight matrix is shared by visible and hidden layers. For instance,
`W1` is shared by `vis` and `hid` layers shown in Figure 1. In SINGA, we can configure
the `share_from` field to enable [parameter sharing]({{ BASE_PATH }}/docs/param)
as shown above for the param `w1` and `w2`.

[Contrastive Divergence]({{ BASE_PATH }}/docs/train-one-batch/#contrastive-divergence)
is configured as the algorithm for [TrainOneBatch]({{ BASE_PATH }}/docs/train-one-batch).
Following Hinton's paper, we configure the [updating protocol]({{ BASE_PATH }}/docs/updater/)
as follows,

    # Updater Configuration
    updater{
      type: kSGD
      momentum: 0.9
      weight_decay: 0.0002
      learning_rate{
        base_lr: 0.1
        type: kFixed
      }
    }

Since the parameters of RBM0 will be used to initialize the auto-encoder, we should
configure the `workspace` field to specify a path for the checkpoint folder.
For example, if we configure it as,

    workspace: "SINGA_ROOT/rbm0/"

Then SINGA will [checkpoint the parameters]({{ BASE_PATH }}/docs/checkpoint) into *SINGA_ROOT/rbm0/*.

### RBM1
<img src="{{ BASE_PATH }}/assets/image/RBM1.PNG" align="center" width="300px"/>
<span><strong>Figure 2 - RBM1</strong></span>

Figure 2 shows the net structure of training RBM1. It is similar to Figure 1,
except that a layer with 500 units is added as the hidden layer of RBM1, and the
visible layer of RBM0 is replaced with a InnerProductLayer and SigmoidLayer which
transforms the image feature using w1 and b1 learned from RBM0.
The neural net configuration is (with layers for data layer and parser layer omittd).

      xxxxx

To load w1 and b1 from RBM0's checkpoint file, we configure the `checkpoint_path` as,

    #zhaojing: add config
    checkpoint_path: "SINGA_ROOT/rbm0/checkpoint/step6000-worker0.bin"
    workspace: "SINGA_ROOT/rbm1"

The workspace is changed for checkpointing w2 and b2 into *SINGA_ROOT/rbm1*.

### RBM2
Figure 2 shows the net structure of training RBM2. One

Step2: Configure a 1000X500 RBM model (RBM1, Figure 2) and load the checkpoint
of RBM0 from "/data/zhaojing/checkpoint/rbm0/checkpoint/step6000-worker0.bin"
by configuring checkpoint_path. Also it should save its checkpoint to
"/data/zhaojing/checkpoint/rbm1/" by configuring workspace.

* The workspace defines the path where this model’s checkpoint is stored and checkpoint_path defines the path where [checkpoint] (http://www.comp.nus.edu.sg/~dbsystem/singa//docs/checkpoint/) is loaded.

Checkpoint Configuration
    checkpoint_after: 500
    checkpoint_freq: 1000
Run Training
    ./bin/singa-run.sh -conf=examples/rbm/job.conf


Configure a 500X250 RBM model (RBM2, Figure 3) and load the checkpoint of RBM1 from "/data/zhaojing/checkpoint/rbm1/checkpoint/step6000-worker0.bin" by configuring checkpoint. Also it should save its checkpoint to "/data/zhaojing/checkpoint/rbm2/" by configuring.

<img src="https://github.com/lzjpaul/incubator-singa/blob/feature-cdrbm-convcommenreb/RBM2.PNG" align="center" width="300px"/>
<span><strong>Figure 3. RBM2</strong></span>

### RBM3
: Configure a 250X30 RBM model (RBM3, Figure 4) and load the checkpoint of RBM2 from "/data/zhaojing/checkpoint/rbm2/checkpoint/step6000-worker0.bin" by configuring checkpoint. Also it should save its checkpoint to "/data/zhaojing/checkpoint/rbm3/" by configuring workspace. But for RBM3 model, it is a linear RBM, so we add a “gaussian” filed in the RBMHid layer and it has a much smaller learning rate.

<img src="https://github.com/lzjpaul/incubator-singa/blob/feature-cdrbm-convcommenreb/RBM3.PNG" align="center" width="300px"/>
<span><strong>Figure 4. RBM3</strong></span>


### RBM4

RBM Layer Configuration
    layer{
      name: "RBMHid"
      type: kRBMHid
      srclayers:"RBMVis"
      rbmhid_conf{
        hid_dim: 30
        gaussian: true
      }
      param{
        name: "w4_1"
        share_from: "w4"
      }
      param{
        name: "rb42"
        init{
        type: kConstant
        value: 0.0
        }
      }
    }
Linear RBM Updater Configuration
    updater{
        type: kSGD
        momentum: 0.9
        weight_decay: 0.0002
        learning_rate{
          base_lr: 0.001
          type: kFixed
        }
    }



### Auto-encoder
In the fine-tuning stage, the 4 RBMs are “unfolded” to form encoder and decoder networks that initially use the same weights.

Step1: Configure an auto encoder with 7 hidden layers (Figure 5). Load the checkpoints of previous 4 RBM models and save its checkpoint to "/data/zhaojing/checkpoint/rbm0/" by configuring workspace

Some important fields of the autoencoder configuration file are shown below. The algorithm we choose is [back propagation (kBP)] (http://www.comp.nus.edu.sg/~dbsystem/singa//docs/train-one-batch/). We use the same cluster configuration as RBM models. For updater, we use AdaGradient algorithm with fixed learning rate.
### Updater Configuration
    updater{
      type: kAdaGrad
      learning_rate{
      base_lr: 0.01
      type: kFixed
      }
    }
### Checkpoint Configuration
    checkpoint_after: 1000
    checkpoint_freq: 1000
    checkpoint_path: "examples/rbm/checkpoint/rbm0/checkpoint/step6000-worker0.bin"
    checkpoint_path: "examples/rbm/checkpoint/rbm1/checkpoint/step6000-worker0.bin"
    checkpoint_path: "examples/rbm/checkpoint/rbm2/checkpoint/step6000-worker0.bin"
    checkpoint_path: "examples/rbm/checkpoint/rbm3/checkpoint/step6000-worker0.bin"
### TrainOneBatch() Function Configuration
    alg: kBP

<img src="https://github.com/lzjpaul/incubator-singa/blob/feature-cdrbm-convcommenreb/autoencoder.PNG" align="center" width="300px"/>
<span><strong>Figure 5. Auto-Encoder</strong></span>

## Visualization Results

Figure 6 visualizes sample columns of the weight matrix of RBM0, We can see the Gabor-like filters are learned. Figure 7 depicts the features extracted from the top-layer of the auto-encoder, wherein one point represents one image. Different colors represent different digits. We can see that most images are well clustered according to the ground truth.
<img src="https://github.com/lzjpaul/incubator-singa/blob/feature-cdrbm-convcommenreb/feature.PNG" align="center" width="300px"/>
<span><strong>Figure 6. Top layer features</strong></span>

<img src="https://github.com/lzjpaul/incubator-singa/blob/feature-cdrbm-convcommenreb/weight.PNG" align="center" width="300px"/>
<span><strong>Figure 7. Bottom RBM weight matrix</strong></span>
