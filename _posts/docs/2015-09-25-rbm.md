---
layout: post
title: Example-Restricted Boltzmann Machine
category : docs
tags : [rbm, example]
---
{% include JB/setup %}

This example uses SINGA to train 4 RBM models and one auto-encoder model over the
[MNIST dataset](http://yann.lecun.com/exdb/mnist/). The auto-encoder model is trained
to reduce the dimensionality of the MNIST image feature. The RBM models are trained
to initialize parameters of the auto-encoder model. This example application is
from [Hinton's science paper](http://www.cs.toronto.edu/~hinton/science.pdf).

## Running instructions

Running scripts are provided in *SINGA_ROOT/examples/rbm* folder.

The MNIST dataset has 70,000 handwritten digit images. The
[data preparation]({{ BASE_PATH }}/docs/data) page
has details on converting this dataset into SINGA recognizable format (i.e.,
[DataShard]({{ BASE_PATH }}/api/classsinga_1_1DataShard.html)). Users can
simply run the following commands to download and convert the dataset.

    # at SINGA_ROOT/examples/rbm/
    $ cp Makefile.example Makefile
    $ make download
    $ make create

The training is separated into two phases, namely pre-training and fine-tuning.
The pre-training phase trains 4 RBMs in sequence,

    # at SINGA_ROOT/
    $ ./bin/singa-run.sh -conf examples/rbm/rbm0.conf
    $ ./bin/singa-run.sh -conf examples/rbm/rbm1.conf
    $ ./bin/singa-run.sh -conf examples/rbm/rbm2.conf
    $ ./bin/singa-run.sh -conf examples/rbm/rbm3.conf

The fine-tuning phase trains the auto-encoder by,

    $ ./bin/singa-run.sh -conf examples/rbm/autoencoder.conf


## Training details

### RBM0

<img src="{{ BASE_PATH }}/assets/image/RBM0.PNG" align="center" width="300px"/>
<span><strong>Figure 1 - RBM0.</strong></span>

The neural net structure for training RBM0 is shown in Figure 1.
The data layer and parser layer provides features for training RBM0.
The visible layer (connected with parser layer) of RBM0 accepts the image feature
(784 dimension). The hidden layer is set to have 1000 neurons (units).
These two layers are configured as,

    layer{
      name: "RBMVis"
      type: kRBMVis
      srclayers:"sigmoid2"
      srclayers:"RBMHid"
      rbmvis_conf{
        num_output: 250
      }
      param{
        name: "w3"
        init{
          type: kGaussian
          mean: 0.0
          std: 0.1
        }
      }
      param{
        name: "rb31"
        init{
          type: kConstant
          value: 0.0
        }
      }
    }

    layer{
      name: "RBMHid"
      type: kRBMHid
      srclayers:"RBMVis"
      rbmhid_conf{
        hid_dim: 250
      }
      param{
        name: "w3_1"
        share_from: "w3"
      }
      param{
        name: "rb32"
        init{
          type: kConstant
          value: 0.0
        }
      }
    }



For RBM, the weight matrix is shared by visible and hidden layers. For instance,
`W1` is shared by `vis` and `hid` layers shown in Figure 1. In SINGA, we can configure
the `share_from` field to enable [parameter sharing]({{ BASE_PATH }}/docs/param)
as shown above for the param `w1` and `w2`.

[Contrastive Divergence]({{ BASE_PATH }}/docs/train-one-batch/#contrastive-divergence)
is configured as the algorithm for [TrainOneBatch]({{ BASE_PATH }}/docs/train-one-batch).
Following Hinton's paper, we configure the [updating protocol]({{ BASE_PATH }}/docs/updater/)
as follows,

    # Updater Configuration
    updater{
      type: kSGD
      momentum: 0.9
      weight_decay: 0.0002
      learning_rate{
        base_lr: 0.1
        type: kFixed
      }
    }

Since the parameters of RBM0 will be used to initialize the auto-encoder, we should
configure the `workspace` field to specify a path for the checkpoint folder.
For example, if we configure it as,

    workspace: "SINGA_ROOT/rbm0/"

Then SINGA will [checkpoint the parameters]({{ BASE_PATH }}/docs/checkpoint) into *SINGA_ROOT/rbm0/*.

### RBM1
<img src="{{ BASE_PATH }}/assets/image/RBM1.PNG" align="center" width="300px"/>
<span><strong>Figure 2 - RBM1</strong></span>

Figure 2 shows the net structure of training RBM1. It is similar to Figure 1,
except that a layer with 500 units is added as the hidden layer of RBM1, and the
visible layer of RBM0 is replaced with a InnerProductLayer and SigmoidLayer which
transforms the image feature using w1 and b1 learned from RBM0.
The neural net configuration is (with layers for data layer and parser layer omittd).

      xxxxx

To load w1 and b1 from RBM0's checkpoint file, we configure the `checkpoint_path` as,

    #zhaojing: add config
    checkpoint_path: "SINGA_ROOT/rbm0/checkpoint/step6000-worker0.bin"
    workspace: "SINGA_ROOT/rbm1"

The workspace is changed for checkpointing w2 and b2 into *SINGA_ROOT/rbm1*.
